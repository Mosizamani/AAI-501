{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc495897",
   "metadata": {},
   "source": [
    "Mostafa Zamaniturk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad784c2f",
   "metadata": {},
   "source": [
    "Assignment 1.1: \n",
    "Submit by Day 7 of the learning week. \n",
    "Instructions \n",
    "1. Consider a rational agent. Suppose the performance measure is concerned with just the first T \n",
    "time steps of the environment and ignores everything thereafter. Use real life examples to show \n",
    "that a rational agent’s action may depend not just on the state of the environment but also on \n",
    "the time step t ≤ T it has reached. [15 points] \n",
    "Hint: Consider any sequential environment in which rewards or goals may take time to arrive. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45703fe",
   "metadata": {},
   "source": [
    "Answer:\n",
    "Consider a rational agent in the form of an inspector drone responsible for checking the safety of a bridge or an airport runway. The drone is programmed to operate over a fixed time horizon of T time steps, and its performance is evaluated only during this period (e.g., a 30-minute inspection window before the next flight or traffic use).\n",
    "\n",
    "Although the environmental state—such as weather conditions, traffic load, or the drone’s current location—may remain the same at different times, the drone's optimal action depends on the current time step t≤T.\n",
    "\n",
    "For instance:\n",
    "\n",
    "At t = 1, the drone has plenty of time, so it may choose to run a detailed scan of a low-risk section to gather more data and calibrate sensors.\n",
    "\n",
    "At t = T–2, with limited time left, the drone might skip less critical areas and prioritize known high-risk zones, even if it's in the same location or environment state as earlier.\n",
    "\n",
    "This illustrates that the same environment state can lead to different actions depending on the time step, because the agent is trying to maximize performance within a limited evaluation window.\n",
    "\n",
    "Therefore, in time-sensitive sequential environments, a rational agent must take into account both the environmental state and the remaining time to act optimally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7413393",
   "metadata": {},
   "source": [
    "2.  For each of the following, provide a description of the task environment and characteristics as \n",
    "described in section 2.3.2 of the book. Your answers should include descriptions in the following \n",
    "order. Do not mix the order in your answers. [20 points] \n",
    " \n",
    "Environment: \n",
    "● Fully observable versus partially observable \n",
    "● Deterministic versus non deterministic/stochastic \n",
    "● Episodic versus sequential \n",
    "● Static versus dynamic \n",
    "● Discrete versus continuous \n",
    " \n",
    "Agent: \n",
    "● Single agent versus multi agent \n",
    " \n",
    "Example question: \n",
    " \n",
    "Playing soccer \n",
    " \n",
    "Answer: Partially observable, stochastic, sequential, dynamic, continuous, multi agent. \n",
    " \n",
    "a) Exploring the subsurface oceans of Titan \n",
    "b) Shopping for used AI books on the internet \n",
    "c) Playing multiple sets (games) in a tennis match \n",
    "d) Bidding on a single item at an auction \n",
    "2 out of 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a74927",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "a) Exploring the subsurface oceans of Titan - Non-observable, Stochastic, Sequential, Dynamic, Discrete, Simple agent\n",
    "\n",
    "b) Shopping for used AI books on the internet - Observable, Stochastic, Episodic, Dynamic, Discrete, Multi agent\n",
    "\n",
    "c) Playing multiple sets (games) in a tennis match - Observable, Multi agent, Stochastic, Sequential, Dynamic, Continuous\n",
    "\n",
    "d) Bidding on a single item at an auction - Non-observable, Multi agent, Stochastic, Episodic, Static, Discrete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cf672e",
   "metadata": {},
   "source": [
    "3. Consider an agent for a vacuum cleaner environment in which the geography of the environment \n",
    "(extent, boundaries, and obstacles) is unknown as is the initial dirt configuration. The agent can \n",
    "go up and down as well as left and right. Can a simple reflex agent be perfectly rational for this \n",
    "environment? Explain in a few sentences using an example scenario [15 points] \n",
    "Project Deliverables and Format: \n",
    "Submit as a single file: Word or PDF. If you take pictures with a phone or scan into PDF, use large font (12 \n",
    "point and up) and high quality. Unreadable cluttered submissions with small font sizes will not be \n",
    "graded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80c4720",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "No, a simple reflex agent cannot be perfectly rational in this environment.\n",
    "\n",
    "A simple reflex agent makes decisions only based on the current percept (e.g., whether there is dirt in the current square) without remembering past actions or considering unseen parts of the environment. In an unknown geography with unknown dirt distribution, the agent needs to explore, avoid revisiting the same places unnecessarily, and remember where it has cleaned.\n",
    "\n",
    "For example, if the agent starts in a corner and cleans that square, it has no way of knowing which direction to go next or whether it has already cleaned a particular area. Without memory, it may get stuck moving back and forth between already clean squares, missing large sections of the environment that still contain dirt. This limitation prevents it from behaving rationally in the long run, as perfect rationality would require systematically covering and cleaning the entire space."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
