{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "345e6c66",
   "metadata": {},
   "source": [
    "# OVERVIEW\n",
    "\n",
    "In this assignment, you will perform a supervised text regression task. The data for the task will consist of student essays from The William and Flora Hewlett Foundation. The dataset was created to assist in the design of solutions for automated grading of student-written essays. You will use a subset of this dataset and predict the scores of the essays. You may not use external data to make predictions. \n",
    "\n",
    "You will be provided with `training_set_rel.tsv` which contain the text of the essay and the score of each essay.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8883c378",
   "metadata": {},
   "source": [
    "# PART 1: SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a454472a",
   "metadata": {},
   "source": [
    "### Q0: Run the following code! \n",
    "    \n",
    "For reproducibility purposes, you will set the random seeds for NumPy and TensorFlow as 1234.  This way, all random steps will produce the same answers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad69bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "seed(1234)\n",
    "\n",
    "tf.random.set_seed(seed = 1234)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2d6a76",
   "metadata": {},
   "source": [
    "### Q1: Load the data\n",
    "\n",
    "We will use data from the [automated essay scoring task](https://www.kaggle.com/c/asap-aes) on Kaggle.\n",
    "\n",
    "We will only use the training data, which we have provided for you -- you don't need to download anything from Kaggle.\n",
    "\n",
    "Access the file `training_set_rel.tsv` as provided.  \n",
    "\n",
    "Use the pandas function `read_csv`, with the parameter `sep=\\t` because this is a tab-separated value file (tsv) and `encoding=latin`. \n",
    "\n",
    "The columns are described on the [Kaggle site](https://www.kaggle.com/competitions/asap-aes/data)\n",
    "\n",
    "We will use three columns: `essay`, `essay_set`, and `domain1_score`.\n",
    "\n",
    "Create a new dataframe with only these three columns, and rename `domain1_score` to just `score`.\n",
    "\n",
    "Display this dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865afe8f",
   "metadata": {},
   "source": [
    "## Graded Cell\n",
    "\n",
    "This cell is worth 5% of the grade for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c81cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a3cb56",
   "metadata": {},
   "source": [
    "### Q2: Select the data from a single essay set\n",
    "\n",
    "There are 8 totally unrelated essay sets in this data.\n",
    "\n",
    "Filter the data frame so we are only considering essay_set = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfb9119",
   "metadata": {},
   "source": [
    "## Graded Cell\n",
    "\n",
    "This cell is worth 5% of the grade for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6c5bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the essay set we are interested in\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75126b2",
   "metadata": {},
   "source": [
    "### Q3: Plot the distribution of scores\n",
    "\n",
    "Create a plot of a histogram of the scores in the training set.  Comment on what you see.  \n",
    "\n",
    "One option is to use the seaborn histplot function.  If you use seaborn, you can use the parameter `bins` to set the bin locations if they look strange. The parameter accepts a list of explicit locations. If you want to center the bins on the tick marks, you cand do something like this:\n",
    "\n",
    "    bins=np.arange(minv,maxv)-0.5\n",
    "    \n",
    "where minv and maxv are the mininmum and maximum value in the range, respectively.   This expression indicates the number of possible scores, and that the tick marks should be at the halfway mark of each bar.\n",
    "\n",
    "You may use some other visualization library if you wish!   The goal is to inspect the distribution of scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb275cd",
   "metadata": {},
   "source": [
    "## Graded Cell\n",
    "\n",
    "This cell is worth 10% of the grade for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd13cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfa2c87",
   "metadata": {},
   "source": [
    "### Q4: Create a test/train split\n",
    "\n",
    "Use the function [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).  Use the `test_size` parameter to control the size of the test set; use 0.2 to indicate a 20% split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de92975b",
   "metadata": {},
   "source": [
    "## Graded Cell\n",
    "\n",
    "This cell is worth 5% of the grade for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09939e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb5389f5",
   "metadata": {},
   "source": [
    "## Part 2: Conventional Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c87581b",
   "metadata": {},
   "source": [
    "### Q5: Create vectors using term frequency\n",
    "\n",
    "Use the `CountVectorizer` class from sklearn to create a vector for each essay.  We can't use text directly with machine learning; we need to create a vector of numbers first.  The CountVectorizer creates a vector with one position for each word in the corpus with a value of the number of occurrences of that word in the essay.\n",
    "\n",
    "The vectorizer works like a model in sklearn: call the fit method on the essay data to \"train\" a model on the training set.  In this situation, we aren't really training anything, but we need a corpus to define the vectors -- only the words in the corpus we use will be represented in the vector.  \n",
    "\n",
    "The fit method returns the trained model.  Now we can use the `transform` method to convert any text into a vector.\n",
    "\n",
    "Call the transform method on the training essays and the test essays to create variables `xtrain` and `xtest`.\n",
    "\n",
    "\n",
    "Report the number of dimensions for each vector; i.e., the number of terms in the corpus. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98afe233",
   "metadata": {},
   "source": [
    "## Graded Cell\n",
    "\n",
    "This cell is worth 10% of the grade for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb97e06d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8063564f",
   "metadata": {},
   "source": [
    "### Q6: Train a regression model using your vectors\n",
    "\n",
    "Now that we have vectors, we can train a regression model to predict the essay score.\n",
    "\n",
    "Use a [`Ridge`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) model from sklearn `linear_model` module.\n",
    "\n",
    "Call the fit method on your training data xtrain and ytrain.\n",
    "\n",
    "Then call the score method on your test data xtest and ytest.  The score method provides a default evaluation metric.  For the Ridge model, the score method returns $R^2$ which is called the coefficient of determination.  It tells you the proportion of the variation in the essay score is predictable from the essay text: higher is better.\n",
    "\n",
    "Report the coefficient of determination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01ffcd6",
   "metadata": {},
   "source": [
    "## Graded Cell\n",
    "\n",
    "This cell is worth 10% of the grade for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce22fc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91ae358d",
   "metadata": {},
   "source": [
    "### Q7: Plot the distribution of scores \n",
    "\n",
    "Plot a histogram of your predicted scores.\n",
    "\n",
    "Plot another histogram of the ground truth scores, superimposed on the first (using seaborn, just call the function again.)\n",
    "\n",
    "How is your model's distribution of scores different from the ground truth distribution?  Describe how they differ; what kind of mistakes is your model making?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40b60c9",
   "metadata": {},
   "source": [
    "## Graded Cell\n",
    "\n",
    "This cell is worth 10% of the grade for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ba56a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43aa0ddc",
   "metadata": {},
   "source": [
    "## Part 3: Neural Network Representations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b89129",
   "metadata": {},
   "source": [
    "For this part, we will implement a deep sentence embedder to replace the feature selection process. As a first step, choose your model from Part 2.\n",
    "\n",
    "This time, you will obtain vectors by using a pre-trained neural network model called the Universal Sentence Encoder.  This model will produce a dense vector from any sequence of text. \n",
    "\n",
    "First, import the model with the following code.  This step will take considerable time -- it is downloading a large pre-trained model for the first time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69573be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "\n",
    "model = hub.load(module_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a9ad5a",
   "metadata": {},
   "source": [
    "### Q8: Generate embeddings\n",
    "\n",
    "Next, you will embed the data with the imported model. The Universal Sentence Encoder takes a list of strings and generates an embedding (i.e., a vector) for each string. \n",
    "\n",
    "You can call the model you downloaded like a function. \n",
    "\n",
    "Generate a vector for each string in the training set; call this array xtrain.\n",
    "\n",
    "Also generate a vector for each string in the test set; call this array xtest.\n",
    "\n",
    "Notice how long this step takes -- it's a big model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05981016",
   "metadata": {},
   "source": [
    "## Graded Cell\n",
    "\n",
    "This cell is worth 5% of the grade for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc4e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43bb7147",
   "metadata": {},
   "source": [
    "### Q9: Train and evaluate a regression model to predict scores using learned embeddings\n",
    "\n",
    "\n",
    "Now retrain your regression model on these learned embeddings instead of the count vectors.\n",
    "\n",
    "Use the vanilla Ridge model.  Report the score. \n",
    "\n",
    "Which model appears to perform the best?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d330337b",
   "metadata": {},
   "source": [
    "## Graded Cell\n",
    "\n",
    "This cell is worth 5% of the grade for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdae5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cb40974",
   "metadata": {},
   "source": [
    "### Q10: Plot the distribution of scores\n",
    "\n",
    "Once again, plot a histogram of your predicted scores from your new model.\n",
    "\n",
    "Plot another histogram of the ground truth scores.\n",
    "\n",
    "How is your new model's distribution of scores different from the ground truth distribution? Is it doing better than your earlier models?  How is it doing better?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc1c593",
   "metadata": {},
   "source": [
    "## Graded Cell\n",
    "\n",
    "This cell is worth 5% of the grade for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b541e587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce0bce69",
   "metadata": {},
   "source": [
    "### Q11: Plot the errors\n",
    "\n",
    "We will analyze the difference between the neural model and your best conventional model.\n",
    "\n",
    "Plot the distribution of errors -- see where the two models made mistakes.\n",
    "\n",
    "The errors are your model's predicted score minus the ground truth human score.\n",
    "\n",
    "Plot a boxplot of the errors for your model using the universal sentence encoder.  Use the seaborn histplot function. \n",
    "\n",
    "x will be the ground truth scores and y is the difference between ground truth and your predictions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f33fe71",
   "metadata": {},
   "source": [
    "## Graded Cell\n",
    "\n",
    "This cell is worth 5% of the grade for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a00c662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc6860d5",
   "metadata": {},
   "source": [
    "### Q12: Compare models directly\n",
    "\n",
    "Plot a histogram of the difference between your neural model and the ground truth.\n",
    "\n",
    "Plot another histogram of the difference between your best conventional model and the ground truth.\n",
    "\n",
    "\n",
    "Does either model tend to overestimate or underestimate the true score?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154dceed",
   "metadata": {},
   "source": [
    "## Graded Cell\n",
    "\n",
    "This cell is worth 10% of the grade for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf10a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code for your plot here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af54a75e",
   "metadata": {},
   "source": [
    "Answer the questions here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61a7fed",
   "metadata": {},
   "source": [
    "### Q13: Summarize your findings\n",
    "\n",
    "Summarize your results. Which approach worked best?  Why?  Does automatic essay scoring appear feasible? How might we improve on this model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1080c3",
   "metadata": {},
   "source": [
    "## Graded Cell\n",
    "\n",
    "This cell is worth 15% of the grade for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcecc87a",
   "metadata": {},
   "source": [
    "#### Write your answers to Q13 here:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
